# Learning Effective Good Variables from Physical Data

This repository contains codes related to the publication ["Learning _Effective Good_ Variables from Physical Data"](https://www.mdpi.com/2504-4990/6/3/77). Datasets and trained models are published on our [Zenodo repository](https://doi.org/10.5281/zenodo.10406490).

## Table of Contents

- [Data folder](#data-folder)
- [Regression workflow](#regression-workflow)
- [Classification workflow](#classification-workflow)

## Data folder

The `Data/` folder contains input datasets used for training and validation.

- Experimental correlations (e.g. Dittus-Boelter, Gnielinski) provided in .xlsx format.
- Datasets for toy problems are generated by the notebooks and can be saved in either .xlsx or .csv format.
- Each file has features (independent variables) in columns and the target variable in the last column.

## Regression workflow

Folder `Regression` contains a Python framework for detecting invariances and extracting physically meaningful variables from regression models.
It contains a modular and refactored implementation with clean separation into Dataset, Model, and Detector components, as well as notebooks to replicate the results included in the [published paper](https://www.mdpi.com/2504-4990/6/3/77) and usage examples.

### ðŸ“‚ Repository Structure

`dataset.py`
Defines the InvarianceDataset class, a wrapper around pandas.DataFrame for handling input features, preprocessing, and preparing data for invariance analysis.

`model.py`
Defines the InvarianceModel class, which wraps a Keras regression model.
Provides training (train()), saving/loading, and gradient extraction capabilities.

`detector.py`
Defines the InvarianceDetector class, implementing the invariance detection pipeline.

- Detects invariant pairs, triplets, and coupled pairs of features.
- Provides plotting utilities to visualize recovered exponents.

`val_correlations/`
Reproducibility notebooks validating the pipeline on known benchmark correlations (e.g. Dittus-Boelter, Gnielinski, Newtonâ€™s gravitation).

`toy_models/`
Example notebooks showing usage of the pipeline on synthetic functions, demonstrating its ability to recover hidden invariances.

`requirements.txt`
Dependencies for installing a dedicated virtual environment.

## Classification workflow

Folder `Classification` contains all `.m` files for finding the optimized mixed features with multi-objective optimization as product combination of the original features. Specifically, the file `MAIN.m` has to be run, deciding how many features to mix and how many mixed features to have in output (1 or 2). The selected threshold(s) and number of bins must be changed in the files `FeatureRoutine1d.m`, `FeatureRoutine1d3class.m`, `FeatureRoutine2d.m`, `DRAWFEATURE1D.m`, `DRAWFEATURE3class.m`, and `DRAWFEATURE2D.m`. Folder `Pareto fronts.m` contains already computed Pareto fronts for the examples shown in this work.

Subfolder `Results` contains the file `Coefficients_mixed_variables.xlsx` with the coefficients for mixing the original features according to the multi-objective optimization.